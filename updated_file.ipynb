{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOSktXwtRL6HYDlWWOrUaXx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swastik-raj-vansh-singh/Diabetes-detection/blob/main/updated_file.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teowcGzQuACj",
        "outputId": "5ddcd2b9-eb9f-4ca9-df66-62e70d1948fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neighbors/_classification.py:233: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return self._fit(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:1183: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1152: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Logistic regression 0.7916666666666666\n",
            "Accuracy K Nearest Neighbours 0.7916666666666666\n",
            "Accuracy Linear SVM 0.7916666666666666\n",
            "Accuracy rbf SVM 0.7708333333333334\n",
            "Accuracy naives bayes 0.796875\n",
            "Accuracy Decision tree 0.7552083333333334\n",
            "Accuracy Random Forest 0.7760416666666666\n",
            "Accuracy voting  0.7864583333333334\n",
            "FEATURE EXTRACTION DONE\n",
            "Accuracy Logistic regression 0.7916666666666666\n",
            "Accuracy K Nearest Neighbours 0.7864583333333334\n",
            "Accuracy Linear SVM 0.78125\n",
            "Accuracy rbf SVM 0.796875\n",
            "Accuracy naives bayes 0.7916666666666666\n",
            "Accuracy Decision tree 0.7291666666666666\n",
            "Accuracy Random Forest 0.7708333333333334\n",
            "Accuracy voting  0.8020833333333334\n",
            "Enter Pregnancies: 1\n",
            "Enter Glucose: 4\n",
            "Enter Blood Pressure: 56\n",
            "Enter Skin Thickness: 54\n",
            "Enter Insulin: 89\n",
            "Enter BMI: 64\n",
            "Enter Diabetes Pedigree Function: 56\n",
            "Enter Age: 44\n",
            "[0]\n",
            "The Patient is NOT Diabetic\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "@author: swastik\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "#CLASSIFICATION MODELS\n",
        "import pandas as pd\n",
        "\n",
        "#IMPORTING THE PIMA INDIAN DIABETES DATASET\n",
        "dataset= pd.read_csv(\"diabetes.csv\")\n",
        "\n",
        "X = dataset.iloc[:,0:8].values\n",
        "y = dataset.iloc[:,8:9].values\n",
        "\n",
        "#TAKING CARE OF MISSING DATA\n",
        "from sklearn.impute import SimpleImputer # Import SimpleImputer instead of Imputer\n",
        "imputer = SimpleImputer(missing_values=0,strategy=\"mean\") # Initialize SimpleImputer\n",
        "imputer = imputer.fit(X[:,0:8])\n",
        "X[:,0:8] = imputer.transform(X[:,0:8])\n",
        "\n",
        "#SPLITTING DATA INTO TRAING SET AND TEST SET\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=0)\n",
        "\n",
        "#FEATURE SCALING\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler();\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "\n",
        "#FITTING OUR MODEL TO VARIOUS CLASSIFICATION MODELS\n",
        "\n",
        "#LOGISTIC REGRESSION\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic_regressor  = LogisticRegression()\n",
        "logistic_regressor.fit(X_train,y_train)\n",
        "\n",
        "print(\"Accuracy Logistic regression\",logistic_regressor.score(X_test,y_test))\n",
        "\n",
        "\n",
        "#NEAREST NEIGHBOUR\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5, metric='minkowski')\n",
        "knn.fit(X_train,y_train)\n",
        "print(\"Accuracy K Nearest Neighbours\",knn.score(X_test,y_test))\n",
        "\n",
        "\n",
        "#SUPPORT VECTOR MACHINE\n",
        "from sklearn.svm import SVC\n",
        "SVM = SVC(kernel ='linear',random_state=0)\n",
        "SVM.fit(X_train,y_train)\n",
        "print(\"Accuracy Linear SVM\",SVM.score(X_test,y_test))\n",
        "\n",
        "#RBF KERNEL SVM\n",
        "rbf_SVM = SVC(kernel=\"rbf\",random_state=0)\n",
        "rbf_SVM.fit(X_train,y_train)\n",
        "print(\"Accuracy rbf SVM\",rbf_SVM.score(X_test,y_test))\n",
        "\n",
        "\n",
        "#NAIVE BAYES CLASSIFIACTION\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "naive_bayes = GaussianNB()\n",
        "naive_bayes.fit(X_test,y_test)\n",
        "print(\"Accuracy naives bayes\",naive_bayes.score(X_test,y_test))\n",
        "\n",
        "\n",
        "#DECISION TREE CLASSIFIER\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "decision_tree = DecisionTreeClassifier(criterion=\"entropy\",random_state=0)\n",
        "decision_tree.fit(X_train,y_train)\n",
        "print(\"Accuracy Decision tree\",decision_tree.score(X_test,y_test))\n",
        "\n",
        "\n",
        "#RANDOM FOREST CLASSIFIER\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "random_forest = RandomForestClassifier(n_estimators=10,criterion=\"entropy\",random_state=0)\n",
        "random_forest.fit(X_train,y_train)\n",
        "print(\"Accuracy Random Forest\",random_forest.score(X_test,y_test))\n",
        "\n",
        "\n",
        "#VOTING CLASSIFIER\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "voting = VotingClassifier(estimators=[('lr',logistic_regressor),('dt',naive_bayes),('SVM',rbf_SVM)],voting='hard')\n",
        "voting.fit(X_train,y_train)\n",
        "print(\"Accuracy voting \",voting.score(X_test,y_test))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"FEATURE EXTRACTION DONE\")\n",
        "#FEATURE EXTRACTION\n",
        "X= dataset.iloc[:,[1,5,6,7]].values\n",
        "y = dataset.iloc[:,8:9].values\n",
        "\n",
        "#TAKING CARE OF MISSING DATA\n",
        "from sklearn.impute import SimpleImputer # Import SimpleImputer from sklearn.impute\n",
        "imputer = SimpleImputer(missing_values=0,strategy=\"mean\") # Use SimpleImputer, remove axis parameter\n",
        "imputer = imputer.fit(X[:,0:8])\n",
        "X[:,0:8] = imputer.transform(X[:,0:8])\n",
        "\n",
        "#SPLITTING DATA INTO TRAING SET AND TEST SET\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=0)\n",
        "\n",
        "#FEATURE SCALING\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler();\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "\n",
        "#FITTING OUR MODEL TO VARIOUS CLASSIFICATION MODELS\n",
        "\n",
        "#LOGISTIC REGRESSION\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logistic_regressor  = LogisticRegression()\n",
        "logistic_regressor.fit(X_train,y_train)\n",
        "print(\"Accuracy Logistic regression\",logistic_regressor.score(X_test,y_test))\n",
        "\n",
        "\n",
        "#NEAREST NEIGHBOUR\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=5, metric='minkowski')\n",
        "knn.fit(X_train,y_train)\n",
        "print(\"Accuracy K Nearest Neighbours\",knn.score(X_test,y_test))\n",
        "\n",
        "\n",
        "#SUPPORT VECTOR MACHINE\n",
        "from sklearn.svm import SVC\n",
        "SVM = SVC(kernel ='linear',random_state=0)\n",
        "SVM.fit(X_train,y_train)\n",
        "print(\"Accuracy Linear SVM\",SVM.score(X_test,y_test))\n",
        "\n",
        "#RBF KERNEL SVM\n",
        "rbf_SVM = SVC(kernel=\"rbf\",random_state=0)\n",
        "rbf_SVM.fit(X_train,y_train)\n",
        "print(\"Accuracy rbf SVM\",rbf_SVM.score(X_test,y_test))\n",
        "\n",
        "\n",
        "#NAIVE BAYES CLASSIFIACTION\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "naive_bayes = GaussianNB()\n",
        "naive_bayes.fit(X_test,y_test)\n",
        "print(\"Accuracy naives bayes\",naive_bayes.score(X_test,y_test))\n",
        "\n",
        "\n",
        "#DECISION TREE CLASSIFIER\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "decision_tree = DecisionTreeClassifier(criterion=\"entropy\",random_state=0)\n",
        "decision_tree.fit(X_train,y_train)\n",
        "print(\"Accuracy Decision tree\",decision_tree.score(X_test,y_test))\n",
        "\n",
        "\n",
        "#RANDOM FOREST CLASSIFIER\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "random_forest = RandomForestClassifier(n_estimators=10,criterion=\"entropy\",random_state=0)\n",
        "random_forest.fit(X_train,y_train)\n",
        "print(\"Accuracy Random Forest\",random_forest.score(X_test,y_test))\n",
        "\n",
        "\n",
        "#VOTING CLASSIFIER\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "voting = VotingClassifier(estimators=[('lr',logistic_regressor),('dt',naive_bayes),('SVM',rbf_SVM)],voting='hard',weights=[1,1,2])\n",
        "voting.fit(X_train,y_train)\n",
        "print(\"Accuracy voting \",voting.score(X_test,y_test))\n",
        "\n",
        "\n",
        "\n",
        "# ... (previous code)\n",
        "\n",
        "# Get input values from the user\n",
        "pregnancies = float(input(\"Enter Pregnancies: \"))\n",
        "glucose = float(input(\"Enter Glucose: \"))\n",
        "blood_pressure = float(input(\"Enter Blood Pressure: \"))\n",
        "skin_thickness = float(input(\"Enter Skin Thickness: \"))\n",
        "insulin = float(input(\"Enter Insulin: \"))\n",
        "bmi = float(input(\"Enter BMI: \"))\n",
        "diabetes_pedigree_function = float(input(\"Enter Diabetes Pedigree Function: \"))\n",
        "age = float(input(\"Enter Age: \"))\n",
        "\n",
        "# Create input array\n",
        "v = [[glucose, insulin, bmi, age]]\n",
        "\n",
        "# Predict using the voting classifier\n",
        "y_pred = voting.predict(v)\n",
        "print(y_pred)\n",
        "\n",
        "if y_pred == 0:\n",
        "    print(\"The Patient is NOT Diabetic\")\n",
        "else:\n",
        "    print(\"The Patient is Diabetic\")"
      ]
    }
  ]
}